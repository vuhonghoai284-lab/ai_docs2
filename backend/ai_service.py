"""AIæœåŠ¡æ¨¡å— - ä½¿ç”¨LangChainè°ƒç”¨OpenAIå…¼å®¹APIï¼ˆä¿®å¤ç‰ˆï¼‰"""
import json
import os
import re
from typing import List, Dict, Optional, Callable
import asyncio
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
from prompt_loader import prompt_loader
from config_loader import get_ai_service_config

# å®šä¹‰æ–‡æ¡£ç« èŠ‚æ¨¡å‹
class DocumentSection(BaseModel):
    """æ–‡æ¡£ç« èŠ‚"""
    section_title: str = Field(description="ç« èŠ‚æ ‡é¢˜")
    content: str = Field(description="ç« èŠ‚å†…å®¹")
    level: int = Field(description="ç« èŠ‚å±‚çº§ï¼Œ1ä¸ºä¸€çº§æ ‡é¢˜ï¼Œ2ä¸ºäºŒçº§æ ‡é¢˜ç­‰")

class DocumentStructure(BaseModel):
    """æ–‡æ¡£ç»“æ„"""
    sections: List[DocumentSection] = Field(description="æ–‡æ¡£ç« èŠ‚åˆ—è¡¨")

# å®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹
class DocumentIssue(BaseModel):
    """æ–‡æ¡£é—®é¢˜æ¨¡å‹"""
    type: str = Field(description="é—®é¢˜ç±»å‹ï¼šè¯­æ³•/é€»è¾‘/å†…å®¹")
    description: str = Field(description="å…·ä½“é—®é¢˜æè¿°")
    location: str = Field(description="é—®é¢˜æ‰€åœ¨ä½ç½®")
    severity: str = Field(description="ä¸¥é‡ç¨‹åº¦ï¼šé«˜/ä¸­/ä½")
    suggestion: str = Field(description="æ”¹è¿›å»ºè®®")

class DocumentIssues(BaseModel):
    """æ–‡æ¡£é—®é¢˜åˆ—è¡¨"""
    issues: List[DocumentIssue] = Field(description="å‘ç°çš„æ‰€æœ‰é—®é¢˜", default=[])

class AIService:
    """AIæœåŠ¡å°è£… - ä½¿ç”¨LangChainå’ŒOpenAIå…¼å®¹API"""
    
    def __init__(self):
        """åˆå§‹åŒ–AIæœåŠ¡"""
        # ä½¿ç”¨é…ç½®åŠ è½½å™¨è·å–é…ç½®
        self.config = get_ai_service_config()
        
        # ä»é…ç½®ä¸­æå–å‚æ•°
        self.provider = self.config['provider']
        self.api_key = self.config['api_key']
        self.api_base = self.config['base_url']
        self.model_name = self.config['model']
        self.temperature = self.config['temperature']
        self.max_tokens = self.config['max_tokens']
        self.timeout = self.config['timeout']
        self.max_retries = self.config['max_retries']
        
        # é™çº§ç­–ç•¥
        self.fallback_enabled = self.config['fallback_enabled']
        self.fallback_provider = self.config['fallback_provider']
        
        print(f"ğŸ¤– AIæœåŠ¡é…ç½®:")
        print(f"   Provider: {self.provider}")
        print(f"   API Base: {self.api_base}")
        print(f"   Model: {self.model_name}")
        print(f"   Temperature: {self.temperature}")
        print(f"   Max Tokens: {self.max_tokens}")
        
        try:
            # åˆå§‹åŒ–ChatOpenAIæ¨¡å‹ï¼ˆå…¼å®¹OpenAIå’ŒAnthropicï¼‰
            self.model = ChatOpenAI(
                api_key=self.api_key,
                base_url=self.api_base,
                model=self.model_name,
                temperature=self.temperature,
                max_tokens=self.max_tokens,
                request_timeout=self.timeout,
                max_retries=self.max_retries
            )
            
            # åˆå§‹åŒ–è§£æå™¨
            self.structure_parser = PydanticOutputParser(pydantic_object=DocumentStructure)
            self.issues_parser = PydanticOutputParser(pydantic_object=DocumentIssues)
            print("âœ… AIæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ AIæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    async def preprocess_document(self, text: str) -> List[Dict]:
        """é¢„å¤„ç†æ–‡æ¡£ï¼šç« èŠ‚åˆ†å‰²å’Œå†…å®¹æ•´ç† - é€šè¿‡AIä¸€æ¬¡æ€§å®Œæˆ"""
        print("ğŸ“ å¼€å§‹æ–‡æ¡£é¢„å¤„ç†...")
        
        try:
            # ä»æ¨¡æ¿åŠ è½½æç¤ºè¯
            system_prompt = prompt_loader.get_system_prompt('document_preprocess')
            
            # æ„å»ºç”¨æˆ·æç¤º
            user_prompt = prompt_loader.get_user_prompt(
                'document_preprocess',
                format_instructions=self.structure_parser.get_format_instructions(),
                document_content=text[:10000]  # é™åˆ¶é•¿åº¦ä»¥é¿å…è¶…å‡ºtokené™åˆ¶
            )

            # åˆ›å»ºæ¶ˆæ¯
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            
            # è°ƒç”¨æ¨¡å‹
            response = await asyncio.to_thread(self.model.invoke, messages)
            
            # è§£æå“åº”
            try:
                content = response.content
                # å°è¯•è§£æJSON
                if isinstance(content, str):
                    # æŸ¥æ‰¾JSONå†…å®¹
                    json_match = re.search(r'\{.*\}', content, re.DOTALL)
                    if json_match:
                        json_str = json_match.group()
                        result = json.loads(json_str)
                    else:
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œè¿”å›åŸæ–‡ä½œä¸ºå•ä¸€ç« èŠ‚
                        result = {
                            "sections": [{
                                "section_title": "æ–‡æ¡£å†…å®¹",
                                "content": text,
                                "level": 1
                            }]
                        }
                else:
                    result = {"sections": [{"section_title": "æ–‡æ¡£å†…å®¹", "content": text, "level": 1}]}
                
                print(f"âœ… æ–‡æ¡£é¢„å¤„ç†å®Œæˆï¼Œè¯†åˆ«åˆ° {len(result.get('sections', []))} ä¸ªç« èŠ‚")
                return result.get('sections', [])
                
            except Exception as e:
                print(f"âš ï¸ æ–‡æ¡£ç»“æ„è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬: {str(e)}")
                return [{"section_title": "æ–‡æ¡£å†…å®¹", "content": text, "level": 1}]
                
        except Exception as e:
            print(f"âŒ æ–‡æ¡£é¢„å¤„ç†å¤±è´¥: {str(e)}")
            # è¿”å›åŸå§‹æ–‡æœ¬ä½œä¸ºå•ä¸€ç« èŠ‚
            return [{"section_title": "æ–‡æ¡£å†…å®¹", "content": text, "level": 1}]
    
    async def detect_issues(self, text: str, progress_callback: Optional[Callable] = None) -> List[Dict]:
        """è°ƒç”¨AIæ£€æµ‹æ–‡æ¡£é—®é¢˜ - ä½¿ç”¨å¼‚æ­¥æ‰¹é‡å¤„ç†"""
        
        # å¦‚æœæ–‡æœ¬å¤ªçŸ­ï¼Œç›´æ¥è¿”å›ç©ºåˆ—è¡¨
        if len(text) < 50:
            return []
        
        # æ›´æ–°è¿›åº¦ï¼šå¼€å§‹æ–‡æ¡£é¢„å¤„ç†
        if progress_callback:
            await progress_callback("æ­£åœ¨åˆ†ææ–‡æ¡£ç»“æ„...", 10)
        
        # å…ˆè¿›è¡Œæ–‡æ¡£é¢„å¤„ç†
        sections = await self.preprocess_document(text)
        total_sections = len(sections)
        
        if progress_callback:
            await progress_callback(f"æ–‡æ¡£å·²æ‹†åˆ†ä¸º {total_sections} ä¸ªç« èŠ‚", 20)
        
        # è¿‡æ»¤æ‰å¤ªçŸ­çš„ç« èŠ‚
        valid_sections = [
            section for section in sections 
            if len(section.get('content', '')) >= 20
        ]
        
        if not valid_sections:
            if progress_callback:
                await progress_callback("æ²¡æœ‰æœ‰æ•ˆçš„ç« èŠ‚éœ€è¦æ£€æµ‹", 100)
            return []
        
        print(f"ğŸ“Š å‡†å¤‡æ£€æµ‹ {len(valid_sections)} ä¸ªæœ‰æ•ˆç« èŠ‚")
        
        # åˆ›å»ºå¼‚æ­¥æ£€æµ‹ä»»åŠ¡
        async def detect_section_issues(section: Dict, index: int) -> List[Dict]:
            """å¼‚æ­¥æ£€æµ‹å•ä¸ªç« èŠ‚çš„é—®é¢˜"""
            section_title = section.get('section_title', 'æœªçŸ¥ç« èŠ‚')
            section_content = section.get('content', '')
            
            # æ›´æ–°è¿›åº¦
            progress = 20 + int((index / len(valid_sections)) * 70)
            if progress_callback:
                await progress_callback(f"æ­£åœ¨æ£€æµ‹ç« èŠ‚ {index + 1}/{len(valid_sections)}: {section_title}", progress)
            
            print(f"ğŸ” [{index + 1}/{len(valid_sections)}] æ£€æµ‹ç« èŠ‚: {section_title}")
            
            try:
                # ä»æ¨¡æ¿åŠ è½½æç¤ºè¯
                system_prompt = prompt_loader.get_system_prompt('document_detect_issues')
                
                # æ„å»ºç”¨æˆ·æç¤º
                user_prompt = prompt_loader.get_user_prompt(
                    'document_detect_issues',
                    section_title=section_title,
                    format_instructions=self.issues_parser.get_format_instructions(),
                    section_content=section_content[:4000]  # é™åˆ¶æ¯ä¸ªç« èŠ‚çš„é•¿åº¦
                )

                # åˆ›å»ºæ¶ˆæ¯
                messages = [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=user_prompt)
                ]
                
                # è°ƒç”¨æ¨¡å‹
                response = await asyncio.to_thread(self.model.invoke, messages)
                
                # è§£æå“åº”
                try:
                    content = response.content
                    if isinstance(content, str):
                        # æŸ¥æ‰¾JSONå†…å®¹
                        json_match = re.search(r'\{.*\}', content, re.DOTALL)
                        if json_match:
                            json_str = json_match.group()
                            result = json.loads(json_str)
                        else:
                            result = {"issues": []}
                    else:
                        result = {"issues": []}
                    
                    # ä¸ºæ¯ä¸ªé—®é¢˜æ·»åŠ ç« èŠ‚ä¿¡æ¯
                    issues = result.get('issues', [])
                    for issue in issues:
                        if 'location' in issue and section_title not in issue.get('location', ''):
                            issue['location'] = f"{section_title} - {issue['location']}"
                    
                    print(f"âœ“ ç« èŠ‚ '{section_title}' æ£€æµ‹å®Œæˆï¼Œå‘ç° {len(issues)} ä¸ªé—®é¢˜")
                    return issues
                    
                except Exception as e:
                    print(f"âš ï¸ è§£æç« èŠ‚ '{section_title}' çš„å“åº”å¤±è´¥: {str(e)}")
                    return []
                    
            except Exception as e:
                print(f"âŒ æ£€æµ‹ç« èŠ‚ '{section_title}' å¤±è´¥: {str(e)}")
                return []
        
        # æ‰¹é‡å¹¶å‘æ‰§è¡Œæ‰€æœ‰ç« èŠ‚çš„æ£€æµ‹
        print(f"ğŸš€ å¼€å§‹å¹¶å‘æ£€æµ‹ {len(valid_sections)} ä¸ªç« èŠ‚...")
        
        # åˆ›å»ºæ‰€æœ‰æ£€æµ‹ä»»åŠ¡
        tasks = [
            detect_section_issues(section, index) 
            for index, section in enumerate(valid_sections)
        ]
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # åˆå¹¶æ‰€æœ‰æ£€æµ‹ç»“æœ
        all_issues = []
        for result in results:
            if isinstance(result, list):
                all_issues.extend(result)
            elif isinstance(result, Exception):
                print(f"âš ï¸ æŸä¸ªç« èŠ‚æ£€æµ‹å‡ºç°å¼‚å¸¸: {str(result)}")
        
        # æ›´æ–°è¿›åº¦ï¼šå®Œæˆ
        if progress_callback:
            await progress_callback(f"æ–‡æ¡£æ£€æµ‹å®Œæˆï¼Œå…±å‘ç° {len(all_issues)} ä¸ªé—®é¢˜", 100)
        
        print(f"âœ… æ–‡æ¡£æ£€æµ‹å®Œæˆï¼Œå…±å‘ç° {len(all_issues)} ä¸ªé—®é¢˜")
        return all_issues
    
    async def call_api(self, prompt: str) -> Dict:
        """é€šç”¨APIè°ƒç”¨æ–¹æ³•"""
        try:
            messages = [HumanMessage(content=prompt)]
            response = await asyncio.to_thread(self.model.invoke, messages)
            return {"status": "success", "content": response.content}
        except Exception as e:
            # å¦‚æœå¯ç”¨äº†é™çº§ç­–ç•¥ï¼Œå¯ä»¥åœ¨è¿™é‡Œå®ç°
            if self.fallback_enabled and self.fallback_provider:
                print(f"âš ï¸ ä¸»æœåŠ¡å¤±è´¥ï¼Œå°è¯•é™çº§åˆ° {self.fallback_provider}")
                # è¿™é‡Œå¯ä»¥å®ç°é™çº§é€»è¾‘
            return {"status": "error", "message": str(e)}