"""é™æ€é—®é¢˜æ£€æµ‹æœåŠ¡ - è´Ÿè´£æ£€æµ‹æ–‡æ¡£ä¸­çš„è´¨é‡é—®é¢˜"""
import json
import re
import time
import logging
import asyncio
from typing import List, Dict, Optional, Callable, Any
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
try:
    from langchain_core.output_parsers import PydanticOutputParser
except ImportError:
    from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session

from app.services.prompt_loader import prompt_loader
from app.models.ai_output import AIOutput
from app.core.config import get_settings


# å®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹
class DocumentIssue(BaseModel):
    """æ–‡æ¡£é—®é¢˜æ¨¡å‹"""
    type: str = Field(description="é—®é¢˜ç±»å‹ï¼š2-6ä¸ªå­—çš„ç®€çŸ­æè¿°ï¼Œå¦‚'é”™åˆ«å­—'ã€'è¯­æ³•é”™è¯¯'ã€'é€»è¾‘ä¸é€š'ã€'å†…å®¹ç¼ºå¤±'ã€'æ ¼å¼é—®é¢˜'ç­‰ï¼Œç”±æ¨¡å‹æ ¹æ®å®é™…é—®é¢˜è‡ªè¡Œåˆ¤æ–­")
    description: str = Field(description="è¯¦ç»†çš„é—®é¢˜æè¿°ï¼Œæ¸…æ™°è¯´æ˜å…·ä½“é—®é¢˜ç‚¹ï¼ŒåŒ…æ‹¬é—®é¢˜çš„è¡¨ç°ã€ä½ç½®å’Œå½±å“ï¼Œè‡³å°‘30å­—ä»¥ä¸Š")
    location: str = Field(description="é—®é¢˜æ‰€åœ¨ä½ç½®")
    severity: str = Field(description="åŸºäºç”¨æˆ·å½±å“ç¨‹åº¦çš„ä¸¥é‡ç­‰çº§ï¼šè‡´å‘½ï¼ˆå¯¼è‡´æ— æ³•ä½¿ç”¨æˆ–ä¸¥é‡è¯¯å¯¼ï¼‰/ä¸¥é‡ï¼ˆå½±å“æ ¸å¿ƒåŠŸèƒ½ç†è§£ï¼‰/ä¸€èˆ¬ï¼ˆå½±å“è´¨é‡ä½†ä¸å½±å“ç†è§£ï¼‰/æç¤ºï¼ˆä¼˜åŒ–å»ºè®®ï¼‰")
    confidence: float = Field(description="æ¨¡å‹å¯¹æ­¤é—®é¢˜åˆ¤å®šçš„ç½®ä¿¡åº¦ï¼ŒèŒƒå›´0.0-1.0", default=0.8)
    suggestion: str = Field(description="ä¿®æ”¹å»ºè®®ï¼šç›´æ¥ç»™å‡ºä¿®æ”¹åçš„å®Œæ•´å†…å®¹ï¼Œè€Œä¸æ˜¯æè¿°å¦‚ä½•ä¿®æ”¹")
    original_text: str = Field(description="åŒ…å«é—®é¢˜çš„åŸæ–‡å†…å®¹å…³é”®ç‰‡æ®µï¼Œ10~30å­—ç¬¦", default="")
    user_impact: str = Field(description="è¯¥é—®é¢˜å¯¹ç”¨æˆ·é˜…è¯»ç†è§£çš„å½±å“ï¼Œ10~30å­—ç¬¦", default="")
    reasoning: str = Field(description="åˆ¤å®šä¸ºé—®é¢˜çš„è¯¦ç»†åˆ†æå’Œæ¨ç†è¿‡ç¨‹ï¼Œ20~100å­—ç¬¦", default="")
    context: str = Field(description="åŒ…å«é—®é¢˜çš„åŸæ–‡å†…å®¹çš„ä¸Šä¸‹æ–‡ç‰‡æ®µå†…å®¹ï¼Œé•¿åº¦20~100å­—ç¬¦", default="")


class DocumentIssues(BaseModel):
    """æ–‡æ¡£é—®é¢˜åˆ—è¡¨"""
    issues: List[DocumentIssue] = Field(description="å‘ç°çš„æ‰€æœ‰é—®é¢˜", default=[])


class IssueDetector:
    """é™æ€é—®é¢˜æ£€æµ‹æœåŠ¡ - ä¸“é—¨è´Ÿè´£æ–‡æ¡£è´¨é‡é—®é¢˜æ£€æµ‹"""
    
    def __init__(self, model_config: Dict, db_session: Optional[Session] = None):
        """
        åˆå§‹åŒ–é—®é¢˜æ£€æµ‹å™¨
        
        Args:
            model_config: AIæ¨¡å‹é…ç½®
            db_session: æ•°æ®åº“ä¼šè¯
        """
        self.db = db_session
        self.model_config = model_config
        
        # åˆå§‹åŒ–æ—¥å¿—
        self.logger = logging.getLogger(f"issue_detector.{id(self)}")
        self.logger.setLevel(logging.INFO)
        
        # ç¡®ä¿æ—¥å¿—èƒ½è¾“å‡ºåˆ°æ§åˆ¶å°
        if not self.logger.handlers:
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            console_handler.setFormatter(formatter)
            self.logger.addHandler(console_handler)
        
        # ä»é…ç½®ä¸­æå–å‚æ•° - ç›´æ¥ä»model_configè·å–ï¼Œå› ä¸ºä¼ å…¥çš„å·²ç»æ˜¯configéƒ¨åˆ†
        self.provider = model_config.get('provider', 'openai')  # è¿™ä¸ªå­—æ®µå¯èƒ½ä¸åœ¨configä¸­
        self.api_key = model_config.get('api_key')
        self.api_base = model_config.get('base_url')
        self.model_name = model_config.get('model')
        self.temperature = model_config.get('temperature', 0.3)
        self.max_tokens = model_config.get('max_tokens', 4000)
        self.timeout = model_config.get('timeout', 60)
        self.max_retries = model_config.get('max_retries', 3)
        
        self.logger.info(f"ğŸ” é—®é¢˜æ£€æµ‹å™¨åˆå§‹åŒ–: Provider={self.provider}, Model={self.model_name}")
        
        try:
            # åˆå§‹åŒ–ChatOpenAIæ¨¡å‹
            self.model = ChatOpenAI(
                api_key=self.api_key,
                base_url=self.api_base,
                model=self.model_name,
                temperature=self.temperature,
                max_tokens=self.max_tokens,
                request_timeout=self.timeout,
                max_retries=self.max_retries
            )
            
            # åˆå§‹åŒ–è§£æå™¨
            self.issues_parser = PydanticOutputParser(pydantic_object=DocumentIssues)
            self.logger.info("âœ… é—®é¢˜æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            self.logger.error(f"âŒ é—®é¢˜æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    async def detect_issues(
        self, 
        sections: List[Dict], 
        task_id: Optional[int] = None,
        progress_callback: Optional[Callable] = None
    ) -> List[Dict]:
        """
        æ£€æµ‹æ–‡æ¡£é—®é¢˜ - ä½¿ç”¨å¼‚æ­¥æ‰¹é‡å¤„ç†
        
        Args:
            sections: æ–‡æ¡£ç« èŠ‚åˆ—è¡¨
            task_id: ä»»åŠ¡ID
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            é—®é¢˜åˆ—è¡¨
        """
        self.logger.info(f"ğŸ” å¼€å§‹æ£€æµ‹æ–‡æ¡£é—®é¢˜ï¼Œå…± {len(sections)} ä¸ªç« èŠ‚")
        
        # è¿‡æ»¤æ‰å¤ªçŸ­çš„ç« èŠ‚
        valid_sections = [
            section for section in sections 
            if len(section.get('content', '')) >= 20
        ]
        
        if not valid_sections:
            if progress_callback:
                await progress_callback("æ²¡æœ‰æœ‰æ•ˆçš„ç« èŠ‚éœ€è¦æ£€æµ‹", 100)
            return []
        
        self.logger.info(f"ğŸ“Š å‡†å¤‡æ£€æµ‹ {len(valid_sections)} ä¸ªæœ‰æ•ˆç« èŠ‚")
        
        if progress_callback:
            await progress_callback(f"å¼€å§‹æ£€æµ‹ {len(valid_sections)} ä¸ªç« èŠ‚çš„é—®é¢˜...", 25)
        
        # åˆ›å»ºå¼‚æ­¥æ£€æµ‹ä»»åŠ¡
        async def detect_section_issues(section: Dict, index: int) -> List[Dict]:
            """å¼‚æ­¥æ£€æµ‹å•ä¸ªç« èŠ‚çš„é—®é¢˜"""
            section_title = section.get('section_title', 'æœªçŸ¥ç« èŠ‚')
            section_content = section.get('content', '')
            section_start_time = time.time()
            
            # æ›´æ–°è¿›åº¦
            progress = 25 + int((index / len(valid_sections)) * 65)
            if progress_callback:
                await progress_callback(f"æ­£åœ¨æ£€æµ‹ç« èŠ‚ {index + 1}/{len(valid_sections)}: {section_title}", progress)
            
            self.logger.debug(f"ğŸ” [{index + 1}/{len(valid_sections)}] æ£€æµ‹ç« èŠ‚: {section_title}")
            
            try:
                # ä»æ¨¡æ¿åŠ è½½æç¤ºè¯
                system_prompt = prompt_loader.get_system_prompt('document_detect_issues')
                
                # æ„å»ºç”¨æˆ·æç¤º
                user_prompt = prompt_loader.get_user_prompt(
                    'document_detect_issues',
                    section_title=section_title,
                    format_instructions=self.issues_parser.get_format_instructions(),
                    section_content=section_content[:4000]  # é™åˆ¶æ¯ä¸ªç« èŠ‚çš„é•¿åº¦
                )

                # åˆ›å»ºæ¶ˆæ¯
                messages = [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=user_prompt)
                ]
                
                # è°ƒç”¨æ¨¡å‹
                self.logger.info(f"ğŸ“¤ è°ƒç”¨æ¨¡å‹æ£€æµ‹ç« èŠ‚ '{section_title}'")
                self.logger.debug(f"System Prompté•¿åº¦: {len(system_prompt)}")
                self.logger.debug(f"User Prompté•¿åº¦: {len(user_prompt)}")
                
                response = await self._call_ai_model(messages)
                processing_time = time.time() - section_start_time
                
                self.logger.info(f"ğŸ“¥ æ”¶åˆ°æ¨¡å‹å“åº” (è€—æ—¶: {processing_time:.2f}s)")
                self.logger.debug(f"åŸå§‹å“åº”å†…å®¹ (å‰500å­—ç¬¦): {str(response.content)[:500]}")
                
                # ä¿å­˜AIè¾“å‡ºåˆ°æ•°æ®åº“
                if self.db and task_id:
                    ai_output = AIOutput(
                        task_id=task_id,
                        operation_type="detect_issues",
                        section_title=section_title,
                        section_index=index,
                        input_text=section_content[:4000],
                        raw_output=response.content,
                        processing_time=processing_time,
                        status="success"
                    )
                
                # è§£æå“åº”
                try:
                    content = response.content
                    self.logger.info(f"ğŸ” å¼€å§‹è§£æç« èŠ‚ '{section_title}' çš„å“åº”")
                    
                    if isinstance(content, str):
                        self.logger.debug(f"å“åº”å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                        
                        # æŸ¥æ‰¾JSONå†…å®¹
                        json_match = re.search(r'\{.*\}', content, re.DOTALL)
                        if json_match:
                            json_str = json_match.group()
                            self.logger.debug(f"æ‰¾åˆ°JSONå†…å®¹ (å‰200å­—ç¬¦): {json_str[:200]}...")
                            
                            try:
                                result = json.loads(json_str)
                                issues_count = len(result.get('issues', []))
                                self.logger.info(f"âœ… JSONè§£ææˆåŠŸï¼ŒåŒ…å« {issues_count} ä¸ªé—®é¢˜")
                            except json.JSONDecodeError as je:
                                self.logger.error(f"âŒ JSONè§£æå¤±è´¥: {str(je)}")
                                self.logger.error(f"JSONå­—ç¬¦ä¸²: {json_str[:500]}...")
                                result = {"issues": []}
                        else:
                            self.logger.warning(f"âš ï¸ æœªæ‰¾åˆ°JSONæ ¼å¼å†…å®¹")
                            self.logger.debug(f"å®Œæ•´å“åº”: {content[:1000]}...")
                            result = {"issues": []}
                    else:
                        self.logger.warning(f"âš ï¸ å“åº”ä¸æ˜¯å­—ç¬¦ä¸²ç±»å‹: {type(content)}")
                        result = {"issues": []}
                    
                    # æ›´æ–°æ•°æ®åº“ä¸­çš„è§£æç»“æœ
                    if self.db and task_id:
                        ai_output.parsed_output = result
                        self.db.add(ai_output)
                        self.db.commit()
                    
                    # ä¸ºæ¯ä¸ªé—®é¢˜æ·»åŠ ç« èŠ‚ä¿¡æ¯
                    issues = result.get('issues', [])
                    for issue in issues:
                        if 'location' in issue and section_title not in issue.get('location', ''):
                            issue['location'] = f"{section_title} - {issue['location']}"
                    
                    self.logger.debug(f"âœ“ ç« èŠ‚ '{section_title}' æ£€æµ‹å®Œæˆï¼Œå‘ç° {len(issues)} ä¸ªé—®é¢˜")
                    return issues
                    
                except Exception as e:
                    import traceback
                    self.logger.error(f"âš ï¸ è§£æç« èŠ‚ '{section_title}' çš„å“åº”å¤±è´¥: {str(e)}")
                    self.logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                    self.logger.error(f"å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
                    
                    # ä¿å­˜è§£æé”™è¯¯ä¿¡æ¯
                    if self.db and task_id:
                        ai_output.status = "parsing_error"
                        ai_output.error_message = str(e)
                        self.db.add(ai_output)
                        self.db.commit()
                    
                    return []
                    
            except Exception as e:
                import traceback
                self.logger.error(f"âŒ æ£€æµ‹ç« èŠ‚ '{section_title}' å¤±è´¥: {str(e)}")
                self.logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                self.logger.error(f"å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
                processing_time = time.time() - section_start_time
                
                # ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°æ•°æ®åº“
                if self.db and task_id:
                    ai_output = AIOutput(
                        task_id=task_id,
                        operation_type="detect_issues",
                        section_title=section_title,
                        section_index=index,
                        input_text=section_content[:4000],
                        raw_output="",
                        status="failed",
                        error_message=str(e),
                        processing_time=processing_time
                    )
                    self.db.add(ai_output)
                    self.db.commit()
                
                return []
        
        # æ‰¹é‡å¹¶å‘æ‰§è¡Œæ‰€æœ‰ç« èŠ‚çš„æ£€æµ‹
        self.logger.info(f"ğŸš€ å¼€å§‹å¹¶å‘æ£€æµ‹ {len(valid_sections)} ä¸ªç« èŠ‚...")
        
        # åˆ›å»ºæ‰€æœ‰æ£€æµ‹ä»»åŠ¡
        tasks = [
            detect_section_issues(section, index) 
            for index, section in enumerate(valid_sections)
        ]
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # åˆå¹¶æ‰€æœ‰æ£€æµ‹ç»“æœ
        all_issues = []
        for result in results:
            if isinstance(result, list):
                all_issues.extend(result)
            elif isinstance(result, Exception):
                self.logger.warning(f"âš ï¸ æŸä¸ªç« èŠ‚æ£€æµ‹å‡ºç°å¼‚å¸¸: {str(result)}")
        
        # æ›´æ–°è¿›åº¦ï¼šå®Œæˆ
        if progress_callback:
            await progress_callback(f"é—®é¢˜æ£€æµ‹å®Œæˆï¼Œå…±å‘ç° {len(all_issues)} ä¸ªé—®é¢˜", 100)
        
        self.logger.info(f"âœ… æ–‡æ¡£æ£€æµ‹å®Œæˆï¼Œå…±å‘ç° {len(all_issues)} ä¸ªé—®é¢˜")
        return all_issues
    
    def filter_issues_by_severity(self, issues: List[Dict], min_confidence: float = 0.6) -> List[Dict]:
        """
        æ ¹æ®ç½®ä¿¡åº¦è¿‡æ»¤é—®é¢˜
        
        Args:
            issues: é—®é¢˜åˆ—è¡¨
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
            
        Returns:
            è¿‡æ»¤åçš„é—®é¢˜åˆ—è¡¨
        """
        filtered_issues = []
        
        for issue in issues:
            confidence = issue.get('confidence', 0.8)
            
            # å¤„ç†éæ•°å­—ç½®ä¿¡åº¦
            try:
                confidence_float = float(confidence)
                if confidence_float >= min_confidence:
                    filtered_issues.append(issue)
                else:
                    self.logger.debug(f"è¿‡æ»¤ä½ç½®ä¿¡åº¦é—®é¢˜: {issue.get('type', 'Unknown')} (ç½®ä¿¡åº¦: {confidence})")
            except (ValueError, TypeError):
                # æ— æ•ˆçš„ç½®ä¿¡åº¦ï¼Œè·³è¿‡æ­¤é—®é¢˜
                self.logger.warning(f"è·³è¿‡æ— æ•ˆç½®ä¿¡åº¦é—®é¢˜: {issue.get('type', 'Unknown')} (ç½®ä¿¡åº¦: {confidence})")
        
        self.logger.info(f"é—®é¢˜è¿‡æ»¤å®Œæˆ: {len(issues)} -> {len(filtered_issues)} (ç½®ä¿¡åº¦ >= {min_confidence})")
        return filtered_issues
    
    def categorize_issues(self, issues: List[Dict]) -> Dict[str, List[Dict]]:
        """
        æŒ‰ä¸¥é‡ç­‰çº§åˆ†ç±»é—®é¢˜
        
        Args:
            issues: é—®é¢˜åˆ—è¡¨
            
        Returns:
            æŒ‰ä¸¥é‡ç­‰çº§åˆ†ç±»çš„é—®é¢˜å­—å…¸
        """
        categories = {
            'è‡´å‘½': [],
            'ä¸¥é‡': [],
            'ä¸€èˆ¬': [],
            'æç¤º': []
        }
        
        for issue in issues:
            severity = issue.get('severity', 'ä¸€èˆ¬')
            if severity in categories:
                categories[severity].append(issue)
            else:
                categories['ä¸€èˆ¬'].append(issue)
        
        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        for severity, severity_issues in categories.items():
            if severity_issues:
                self.logger.info(f"ğŸ“Š {severity}é—®é¢˜: {len(severity_issues)} ä¸ª")
        
        return categories
    
    async def _call_ai_model(self, messages):
        """
        è°ƒç”¨AIæ¨¡å‹ï¼ˆä»…åœ¨æ­¤æ–¹æ³•å†…è¿›è¡Œmockåˆ¤æ–­ï¼‰
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            AIæ¨¡å‹å“åº”
        """
        # ç›´æ¥è¿›è¡ŒçœŸå®çš„AIè°ƒç”¨
        return await asyncio.to_thread(self.model.invoke, messages)
    
    async def analyze_document(self, text: str, prompt_type: str = "detect_issues") -> Dict[str, Any]:
        """
        ç»Ÿä¸€çš„æ–‡æ¡£åˆ†ææ¥å£ï¼Œå…¼å®¹task_processorçš„è°ƒç”¨
        
        Args:
            text: æ–‡æ¡£æ–‡æœ¬å†…å®¹
            prompt_type: æç¤ºç±»å‹ï¼Œå¯¹äºIssueDetectorä»…æ”¯æŒ"detect_issues"
            
        Returns:
            åˆ†æç»“æœ
        """
        if prompt_type != "detect_issues":
            raise ValueError(f"IssueDetectoråªæ”¯æŒdetect_issuesç±»å‹ï¼Œæ”¶åˆ°: {prompt_type}")
        
        # å°†æ–‡æœ¬è½¬æ¢ä¸ºç« èŠ‚æ ¼å¼ï¼Œä»¥ä¾¿è°ƒç”¨detect_issuesæ–¹æ³•
        sections = [{"section_title": "æ–‡æ¡£å†…å®¹", "content": text, "level": 1}]
        
        # è°ƒç”¨é—®é¢˜æ£€æµ‹æ–¹æ³•
        issues = await self.detect_issues(sections)
        
        # æ„å»ºè¿”å›æ ¼å¼ï¼Œå…¼å®¹task_processorçš„æœŸæœ›
        return {
            "status": "success",
            "data": {
                "issues": issues,
                "summary": {
                    "total_issues": len(issues),
                    "critical": sum(1 for i in issues if i.get("severity") == "è‡´å‘½"),
                    "major": sum(1 for i in issues if i.get("severity") == "ä¸¥é‡"),
                    "normal": sum(1 for i in issues if i.get("severity") == "ä¸€èˆ¬"),
                    "minor": sum(1 for i in issues if i.get("severity") == "æç¤º")
                }
            },
            "raw_output": json.dumps({"issues": issues}, ensure_ascii=False, indent=2),
            "tokens_used": 200,  # ä¼°ç®—å€¼
            "processing_time": 2.0  # ä¼°ç®—å€¼
        }