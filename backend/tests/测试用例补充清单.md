# 测试用例补充清单

## 目录结构建议

```
tests/
├── unit/                           # 单元测试
│   ├── services/                   # 服务层测试
│   │   ├── test_task_processor.py
│   │   ├── test_document_processor.py
│   │   ├── test_issue_detector.py
│   │   ├── test_ai_service_factory.py
│   │   └── test_auth_service.py
│   ├── repositories/               # 数据访问层测试
│   │   ├── test_task_repository.py
│   │   ├── test_user_repository.py
│   │   ├── test_issue_repository.py
│   │   └── test_ai_output_repository.py
│   └── models/                     # 模型测试
│       ├── test_task_model.py
│       ├── test_user_model.py
│       └── test_issue_model.py
├── integration/                    # 集成测试
│   ├── test_ai_service_integration.py
│   ├── test_database_integration.py
│   └── test_file_system_integration.py
├── performance/                    # 性能测试
│   ├── test_api_performance.py
│   ├── test_document_processing_performance.py
│   └── test_concurrent_load.py
├── security/                       # 安全测试
│   ├── test_input_validation.py
│   ├── test_file_upload_security.py
│   └── test_authentication_security.py
├── fixtures/                       # 测试数据和工具
│   ├── factories.py
│   ├── mock_data.py
│   └── test_helpers.py
└── e2e/                           # 端到端测试（已存在）
    └── test_full_workflow.py
```

---

## 1. 单元测试用例

### 1.1 TaskProcessor单元测试

**文件**: `tests/unit/services/test_task_processor.py`

```python
import pytest
from unittest.mock import Mock, patch, AsyncMock
import asyncio
from app.services.task_processor import TaskProcessor
from app.models.task import Task

class TestTaskProcessor:
    """任务处理器单元测试"""
    
    @pytest.fixture
    def mock_dependencies(self):
        """Mock所有依赖"""
        with patch.multiple(
            'app.services.task_processor',
            TaskRepository=Mock(),
            IssueRepository=Mock(),
            AIOutputRepository=Mock(),
            FileInfoRepository=Mock(),
            AIModelRepository=Mock(),
            AIServiceFactory=Mock(),
            manager=Mock()
        ) as mocks:
            yield mocks
    
    @pytest.fixture
    def task_processor(self, mock_dependencies):
        """创建TaskProcessor实例"""
        mock_db = Mock()
        return TaskProcessor(mock_db)
    
    async def test_process_task_normal_flow(self, task_processor, mock_dependencies):
        """测试正常任务处理流程"""
        # 准备测试数据
        task_id = 1
        mock_task = Mock()
        mock_task.id = task_id
        mock_task.status = "pending"
        
        # 配置Mock行为
        task_processor.task_repo.get.return_value = mock_task
        task_processor.file_repo.get_by_task_id.return_value = Mock()
        task_processor.ai_service_factory.get_service.return_value = Mock()
        
        # 执行测试
        await task_processor.process_task(task_id)
        
        # 验证结果
        task_processor.task_repo.update.assert_called()
        assert task_processor.task_repo.update.call_count >= 2  # 至少更新2次状态
    
    async def test_process_task_not_found(self, task_processor, mock_dependencies):
        """测试任务不存在的情况"""
        # 配置Mock：任务不存在
        task_processor.task_repo.get.return_value = None
        
        # 执行测试并验证异常
        with pytest.raises(ValueError, match="任务不存在"):
            await task_processor.process_task(999)
    
    async def test_process_task_file_not_found(self, task_processor, mock_dependencies):
        """测试文件不存在的情况"""
        # 准备测试数据
        mock_task = Mock()
        mock_task.id = 1
        
        # 配置Mock：任务存在但文件不存在
        task_processor.task_repo.get.return_value = mock_task
        task_processor.file_repo.get_by_task_id.return_value = None
        
        # 执行测试
        await task_processor.process_task(1)
        
        # 验证错误处理
        task_processor.task_repo.update.assert_called_with(1, status="failed")
    
    async def test_process_task_ai_service_failure(self, task_processor, mock_dependencies):
        """测试AI服务调用失败"""
        # 准备测试数据
        mock_task = Mock()
        mock_file = Mock()
        mock_ai_service = Mock()
        mock_ai_service.analyze_document.side_effect = Exception("AI服务异常")
        
        # 配置Mock
        task_processor.task_repo.get.return_value = mock_task
        task_processor.file_repo.get_by_task_id.return_value = mock_file
        task_processor.ai_service_factory.get_service.return_value = mock_ai_service
        
        # 执行测试
        await task_processor.process_task(1)
        
        # 验证错误处理
        task_processor.task_repo.update.assert_called_with(1, status="failed")
    
    async def test_process_task_retry_mechanism(self, task_processor, mock_dependencies):
        """测试任务重试机制"""
        # 配置Mock：前两次失败，第三次成功
        call_count = 0
        def side_effect(*args, **kwargs):
            nonlocal call_count
            call_count += 1
            if call_count <= 2:
                raise Exception("暂时失败")
            return {"issues": []}
        
        mock_ai_service = Mock()
        mock_ai_service.analyze_document.side_effect = side_effect
        
        task_processor.task_repo.get.return_value = Mock()
        task_processor.file_repo.get_by_task_id.return_value = Mock()
        task_processor.ai_service_factory.get_service.return_value = mock_ai_service
        
        # 执行测试
        await task_processor.process_task(1)
        
        # 验证重试次数
        assert mock_ai_service.analyze_document.call_count == 3
```

### 1.2 DocumentProcessor单元测试

**文件**: `tests/unit/services/test_document_processor.py`

```python
import pytest
from unittest.mock import Mock, patch, mock_open
from app.services.document_processor import DocumentProcessor

class TestDocumentProcessor:
    """文档处理器单元测试"""
    
    @pytest.fixture
    def document_processor(self):
        return DocumentProcessor()
    
    def test_process_markdown_content(self, document_processor):
        """测试Markdown内容处理"""
        content = "# 标题\n\n这是测试内容。\n\n## 子标题\n\n更多内容。"
        
        result = document_processor.process_content(content, "markdown")
        
        assert result["content_type"] == "markdown"
        assert "标题" in result["text"]
        assert result["word_count"] > 0
        assert len(result["sections"]) >= 2
    
    def test_process_large_content_chunking(self, document_processor):
        """测试大内容分块处理"""
        # 创建超过8000字符的内容
        large_content = "测试内容。" * 2000  # 约10000字符
        
        result = document_processor.process_content(large_content, "text")
        
        assert len(result["chunks"]) > 1
        assert all(len(chunk) <= 8000 for chunk in result["chunks"])
    
    def test_extract_text_from_pdf(self, document_processor):
        """测试PDF文本提取"""
        mock_pdf_content = b"%PDF-1.4 mock content"
        
        with patch('PyPDF2.PdfReader') as mock_reader:
            mock_page = Mock()
            mock_page.extract_text.return_value = "PDF测试内容"
            mock_reader.return_value.pages = [mock_page]
            
            result = document_processor.extract_text_from_pdf(mock_pdf_content)
            
            assert "PDF测试内容" in result
    
    def test_extract_text_from_invalid_pdf(self, document_processor):
        """测试无效PDF处理"""
        invalid_content = b"这不是PDF文件"
        
        with pytest.raises(Exception):
            document_processor.extract_text_from_pdf(invalid_content)
    
    def test_detect_encoding(self, document_processor):
        """测试编码检测"""
        utf8_content = "中文测试内容".encode('utf-8')
        gbk_content = "中文测试内容".encode('gbk')
        
        encoding1 = document_processor.detect_encoding(utf8_content)
        encoding2 = document_processor.detect_encoding(gbk_content)
        
        assert encoding1 in ['utf-8', 'UTF-8']
        assert encoding2 in ['gbk', 'GBK', 'gb2312']
    
    def test_process_empty_content(self, document_processor):
        """测试空内容处理"""
        result = document_processor.process_content("", "text")
        
        assert result["text"] == ""
        assert result["word_count"] == 0
        assert len(result["sections"]) == 0
```

### 1.3 IssueDetector单元测试

**文件**: `tests/unit/services/test_issue_detector.py`

```python
import pytest
from unittest.mock import Mock, patch
from app.services.issue_detector import IssueDetector

class TestIssueDetector:
    """问题检测器单元测试"""
    
    @pytest.fixture
    def issue_detector(self):
        return IssueDetector()
    
    def test_detect_grammar_issues(self, issue_detector):
        """测试语法问题检测"""
        text_with_issues = "这是一个有语法问题句子。"  # 缺少"的"
        
        issues = issue_detector.detect_grammar_issues(text_with_issues)
        
        assert len(issues) > 0
        assert any(issue["type"] == "grammar" for issue in issues)
    
    def test_detect_logic_issues(self, issue_detector):
        """测试逻辑问题检测"""
        contradictory_text = """
        系统支持Windows和Linux操作系统。
        该系统只能在Windows上运行。
        """
        
        issues = issue_detector.detect_logic_issues(contradictory_text)
        
        assert len(issues) > 0
        assert any(issue["type"] == "logic" for issue in issues)
    
    def test_detect_completeness_issues(self, issue_detector):
        """测试完整性问题检测"""
        incomplete_text = "安装步骤：1. 下载文件 2. 解压文件"  # 缺少后续步骤
        
        issues = issue_detector.detect_completeness_issues(incomplete_text)
        
        assert len(issues) > 0
        assert any(issue["type"] == "completeness" for issue in issues)
    
    def test_classify_issue_severity(self, issue_detector):
        """测试问题严重性分类"""
        critical_issue = {"description": "系统崩溃", "type": "error"}
        minor_issue = {"description": "标点符号错误", "type": "grammar"}
        
        severity1 = issue_detector.classify_severity(critical_issue)
        severity2 = issue_detector.classify_severity(minor_issue)
        
        assert severity1 in ["high", "critical"]
        assert severity2 in ["low", "minor"]
    
    def test_remove_duplicate_issues(self, issue_detector):
        """测试重复问题去除"""
        issues = [
            {"description": "相同问题", "location": "第1行"},
            {"description": "相同问题", "location": "第2行"},
            {"description": "不同问题", "location": "第3行"}
        ]
        
        unique_issues = issue_detector.remove_duplicates(issues)
        
        assert len(unique_issues) == 2
    
    def test_calculate_confidence_score(self, issue_detector):
        """测试置信度计算"""
        high_confidence_issue = {
            "type": "grammar",
            "evidence": ["明确的语法错误", "多处类似错误"]
        }
        
        low_confidence_issue = {
            "type": "style",
            "evidence": ["可能的风格问题"]
        }
        
        score1 = issue_detector.calculate_confidence(high_confidence_issue)
        score2 = issue_detector.calculate_confidence(low_confidence_issue)
        
        assert score1 > score2
        assert 0 <= score1 <= 1
        assert 0 <= score2 <= 1
```

---

## 2. Repository单元测试

### 2.1 TaskRepository单元测试

**文件**: `tests/unit/repositories/test_task_repository.py`

```python
import pytest
from unittest.mock import Mock
from sqlalchemy.orm import Session
from app.repositories.task import TaskRepository
from app.models.task import Task
from app.dto.task import TaskCreate

class TestTaskRepository:
    """任务仓储单元测试"""
    
    @pytest.fixture
    def mock_db(self):
        return Mock(spec=Session)
    
    @pytest.fixture
    def task_repo(self, mock_db):
        return TaskRepository(mock_db)
    
    def test_create_task(self, task_repo, mock_db):
        """测试创建任务"""
        task_data = TaskCreate(
            title="测试任务",
            file_name="test.md",
            file_path="/path/to/test.md",
            user_id=1,
            model_id=1
        )
        
        # 模拟数据库返回
        mock_task = Mock()
        mock_task.id = 1
        mock_db.add.return_value = None
        mock_db.commit.return_value = None
        mock_db.refresh.return_value = None
        
        with patch('app.models.task.Task') as MockTask:
            MockTask.return_value = mock_task
            
            result = task_repo.create(task_data)
            
            # 验证调用
            mock_db.add.assert_called_once()
            mock_db.commit.assert_called_once()
            mock_db.refresh.assert_called_once_with(mock_task)
            assert result == mock_task
    
    def test_get_task_by_id(self, task_repo, mock_db):
        """测试根据ID获取任务"""
        task_id = 1
        mock_task = Mock()
        mock_db.query.return_value.filter.return_value.first.return_value = mock_task
        
        result = task_repo.get_by_id(task_id)
        
        mock_db.query.assert_called_with(Task)
        assert result == mock_task
    
    def test_get_task_by_user_id(self, task_repo, mock_db):
        """测试根据用户ID获取任务列表"""
        user_id = 1
        mock_tasks = [Mock(), Mock()]
        mock_db.query.return_value.filter.return_value.all.return_value = mock_tasks
        
        result = task_repo.get_by_user_id(user_id)
        
        mock_db.query.assert_called_with(Task)
        assert result == mock_tasks
    
    def test_update_task_status(self, task_repo, mock_db):
        """测试更新任务状态"""
        task_id = 1
        new_status = "completed"
        
        mock_task = Mock()
        mock_db.query.return_value.filter.return_value.first.return_value = mock_task
        
        result = task_repo.update_status(task_id, new_status)
        
        assert mock_task.status == new_status
        mock_db.commit.assert_called_once()
        assert result == mock_task
    
    def test_delete_task(self, task_repo, mock_db):
        """测试删除任务"""
        task_id = 1
        mock_task = Mock()
        mock_db.query.return_value.filter.return_value.first.return_value = mock_task
        
        result = task_repo.delete(task_id)
        
        mock_db.delete.assert_called_once_with(mock_task)
        mock_db.commit.assert_called_once()
        assert result is True
    
    def test_delete_nonexistent_task(self, task_repo, mock_db):
        """测试删除不存在的任务"""
        task_id = 999
        mock_db.query.return_value.filter.return_value.first.return_value = None
        
        result = task_repo.delete(task_id)
        
        mock_db.delete.assert_not_called()
        assert result is False
```

---

## 3. 集成测试用例

### 3.1 AI服务集成测试

**文件**: `tests/integration/test_ai_service_integration.py`

```python
import pytest
import asyncio
from unittest.mock import patch
from app.services.ai_service_factory import AIServiceFactory
from app.models.ai_model import AIModel

class TestAIServiceIntegration:
    """AI服务集成测试"""
    
    @pytest.fixture
    def ai_model(self):
        return AIModel(
            model_key="gpt-4o-mini",
            label="GPT-4o Mini",
            provider="openai",
            model_name="gpt-4o-mini",
            is_active=True
        )
    
    @pytest.fixture
    def ai_service_factory(self):
        return AIServiceFactory()
    
    async def test_ai_service_document_analysis(self, ai_service_factory, ai_model):
        """测试AI服务文档分析"""
        service = ai_service_factory.get_service(ai_model)
        
        test_content = """
        # 测试文档
        
        这是一个测试文档，用于验证AI分析功能。
        该文档包含一些基本内容。
        """
        
        # 在测试模式下应该返回Mock结果
        result = await service.analyze_document(test_content)
        
        assert "issues" in result
        assert isinstance(result["issues"], list)
    
    async def test_ai_service_timeout_handling(self, ai_service_factory, ai_model):
        """测试AI服务超时处理"""
        service = ai_service_factory.get_service(ai_model)
        
        # 模拟超时情况
        with patch.object(service, '_call_ai_api') as mock_call:
            mock_call.side_effect = asyncio.TimeoutError("请求超时")
            
            with pytest.raises(asyncio.TimeoutError):
                await service.analyze_document("测试内容")
    
    async def test_ai_service_error_handling(self, ai_service_factory, ai_model):
        """测试AI服务错误处理"""
        service = ai_service_factory.get_service(ai_model)
        
        # 模拟API错误
        with patch.object(service, '_call_ai_api') as mock_call:
            mock_call.side_effect = Exception("API调用失败")
            
            with pytest.raises(Exception):
                await service.analyze_document("测试内容")
    
    async def test_ai_service_response_validation(self, ai_service_factory, ai_model):
        """测试AI服务响应验证"""
        service = ai_service_factory.get_service(ai_model)
        
        # 模拟无效响应
        with patch.object(service, '_call_ai_api') as mock_call:
            mock_call.return_value = {"invalid": "response"}
            
            result = await service.analyze_document("测试内容")
            
            # 验证服务能够处理无效响应
            assert "issues" in result
            assert isinstance(result["issues"], list)
```

---

## 4. 性能测试用例

### 4.1 API性能测试

**文件**: `tests/performance/test_api_performance.py`

```python
import pytest
import time
import statistics
from fastapi.testclient import TestClient

class TestAPIPerformance:
    """API性能测试"""
    
    def test_create_task_performance(self, client: TestClient, auth_headers, sample_file):
        """测试创建任务API性能"""
        filename, content, content_type = sample_file
        files = {"file": (filename, content, content_type)}
        data = {"model_index": "0"}
        
        # 执行多次请求测量性能
        response_times = []
        for _ in range(10):
            start_time = time.time()
            response = client.post("/api/tasks", files=files, data=data, headers=auth_headers)
            end_time = time.time()
            
            assert response.status_code == 200
            response_times.append((end_time - start_time) * 1000)  # 转换为毫秒
        
        # 性能断言
        avg_time = statistics.mean(response_times)
        max_time = max(response_times)
        
        assert avg_time < 500, f"平均响应时间过长: {avg_time:.2f}ms"
        assert max_time < 1000, f"最大响应时间过长: {max_time:.2f}ms"
    
    def test_get_tasks_performance(self, client: TestClient, auth_headers):
        """测试获取任务列表API性能"""
        response_times = []
        
        for _ in range(20):
            start_time = time.time()
            response = client.get("/api/tasks", headers=auth_headers)
            end_time = time.time()
            
            assert response.status_code == 200
            response_times.append((end_time - start_time) * 1000)
        
        avg_time = statistics.mean(response_times)
        assert avg_time < 100, f"获取任务列表响应时间过长: {avg_time:.2f}ms"
    
    def test_concurrent_request_performance(self, client: TestClient, auth_headers):
        """测试并发请求性能"""
        import threading
        import queue
        
        result_queue = queue.Queue()
        
        def make_request():
            start_time = time.time()
            response = client.get("/api/tasks", headers=auth_headers)
            end_time = time.time()
            result_queue.put({
                "status_code": response.status_code,
                "response_time": (end_time - start_time) * 1000
            })
        
        # 启动10个并发请求
        threads = []
        for _ in range(10):
            thread = threading.Thread(target=make_request)
            threads.append(thread)
            thread.start()
        
        # 等待所有请求完成
        for thread in threads:
            thread.join()
        
        # 收集结果
        results = []
        while not result_queue.empty():
            results.append(result_queue.get())
        
        # 性能断言
        assert len(results) == 10
        assert all(r["status_code"] == 200 for r in results)
        
        avg_time = statistics.mean([r["response_time"] for r in results])
        assert avg_time < 200, f"并发请求平均响应时间过长: {avg_time:.2f}ms"
```

---

## 5. 安全测试用例

### 5.1 输入验证安全测试

**文件**: `tests/security/test_input_validation.py`

```python
import pytest
from fastapi.testclient import TestClient

class TestInputValidationSecurity:
    """输入验证安全测试"""
    
    def test_sql_injection_prevention(self, client: TestClient, auth_headers):
        """测试SQL注入防护"""
        # SQL注入攻击载荷
        malicious_payloads = [
            "'; DROP TABLE users; --",
            "' OR '1'='1",
            "' UNION SELECT * FROM users --",
            "admin'--",
            "admin' /*"
        ]
        
        for payload in malicious_payloads:
            # 尝试在任务标题中注入SQL
            response = client.post(
                "/api/tasks",
                files={"file": ("test.md", b"test content", "text/markdown")},
                data={"title": payload, "model_index": "0"},
                headers=auth_headers
            )
            
            # 验证系统正确处理了恶意输入
            assert response.status_code in [200, 400, 422]
            
            # 如果创建成功，验证payload被正确转义
            if response.status_code == 200:
                task = response.json()
                assert "DROP TABLE" not in task.get("title", "")
    
    def test_xss_prevention(self, client: TestClient, auth_headers):
        """测试XSS攻击防护"""
        xss_payloads = [
            "<script>alert('xss')</script>",
            "javascript:alert('xss')",
            "<img src=x onerror=alert('xss')>",
            "<svg onload=alert('xss')>",
            "';alert('xss');//"
        ]
        
        for payload in xss_payloads:
            response = client.post(
                "/api/tasks",
                files={"file": ("test.md", b"test content", "text/markdown")},
                data={"title": payload, "model_index": "0"},
                headers=auth_headers
            )
            
            if response.status_code == 200:
                task = response.json()
                title = task.get("title", "")
                
                # 验证危险脚本被转义或移除
                assert "<script>" not in title
                assert "javascript:" not in title
                assert "onerror=" not in title
    
    def test_path_traversal_prevention(self, client: TestClient, auth_headers):
        """测试路径遍历攻击防护"""
        malicious_filenames = [
            "../../../etc/passwd",
            "..\\..\\..\\windows\\system32\\config\\sam",
            "/etc/passwd",
            "C:\\windows\\system32\\config\\sam",
            "....//....//....//etc/passwd"
        ]
        
        for filename in malicious_filenames:
            response = client.post(
                "/api/tasks",
                files={"file": (filename, b"malicious content", "text/plain")},
                data={"model_index": "0"},
                headers=auth_headers
            )
            
            # 系统应该拒绝或安全处理恶意文件名
            if response.status_code == 200:
                task = response.json()
                file_name = task.get("file_name", "")
                
                # 验证文件名被安全处理
                assert "../" not in file_name
                assert "..\\" not in file_name
                assert "/etc/" not in file_name
    
    def test_file_upload_size_limit(self, client: TestClient, auth_headers):
        """测试文件上传大小限制"""
        # 创建超大文件（超过限制）
        oversized_content = b"x" * (50 * 1024 * 1024)  # 50MB
        
        response = client.post(
            "/api/tasks",
            files={"file": ("large.md", oversized_content, "text/markdown")},
            data={"model_index": "0"},
            headers=auth_headers
        )
        
        # 验证大文件被拒绝
        assert response.status_code == 400
        assert "文件大小超过限制" in response.json()["detail"]
    
    def test_file_type_validation(self, client: TestClient, auth_headers):
        """测试文件类型验证"""
        dangerous_files = [
            ("malware.exe", b"MZ\x90\x00", "application/x-executable"),
            ("script.php", b"<?php system($_GET['cmd']); ?>", "application/x-php"),
            ("shell.sh", b"#!/bin/bash\nrm -rf /", "application/x-sh"),
            ("virus.bat", b"@echo off\ndel /f /q *.*", "application/x-bat")
        ]
        
        for filename, content, content_type in dangerous_files:
            response = client.post(
                "/api/tasks",
                files={"file": (filename, content, content_type)},
                data={"model_index": "0"},
                headers=auth_headers
            )
            
            # 验证危险文件类型被拒绝
            assert response.status_code == 400
            assert "不支持的文件类型" in response.json()["detail"]
```

---

## 6. 测试工具和辅助文件

### 6.1 测试数据工厂

**文件**: `tests/fixtures/factories.py`

```python
import factory
from datetime import datetime
from app.models.user import User
from app.models.task import Task
from app.models.ai_model import AIModel
from app.models.file_info import FileInfo

class UserFactory(factory.Factory):
    """用户数据工厂"""
    class Meta:
        model = User
    
    uid = factory.Sequence(lambda n: f"user_{n}")
    display_name = factory.Faker("name")
    email = factory.LazyAttribute(lambda obj: f"{obj.uid}@test.com")
    is_admin = False
    is_system_admin = False
    created_at = factory.LazyFunction(datetime.utcnow)

class AdminUserFactory(UserFactory):
    """管理员用户工厂"""
    is_admin = True
    is_system_admin = True

class AIModelFactory(factory.Factory):
    """AI模型数据工厂"""
    class Meta:
        model = AIModel
    
    model_key = factory.Sequence(lambda n: f"model_{n}")
    label = factory.Faker("word")
    provider = factory.Iterator(["openai", "anthropic", "google"])
    model_name = factory.LazyAttribute(lambda obj: f"{obj.provider}_model")
    is_active = True
    is_default = False

class TaskFactory(factory.Factory):
    """任务数据工厂"""
    class Meta:
        model = Task
    
    title = factory.Faker("sentence", nb_words=4)
    file_name = factory.Faker("file_name", extension="md")
    file_path = factory.LazyAttribute(lambda obj: f"/uploads/{obj.file_name}")
    status = "pending"
    progress = 0
    user = factory.SubFactory(UserFactory)
    model = factory.SubFactory(AIModelFactory)
    created_at = factory.LazyFunction(datetime.utcnow)

class FileInfoFactory(factory.Factory):
    """文件信息数据工厂"""
    class Meta:
        model = FileInfo
    
    original_name = factory.Faker("file_name", extension="md")
    file_path = factory.LazyAttribute(lambda obj: f"/uploads/{obj.original_name}")
    file_size = factory.Faker("random_int", min=1000, max=1000000)
    content_type = "text/markdown"
    task = factory.SubFactory(TaskFactory)
```

### 6.2 Mock数据和工具

**文件**: `tests/fixtures/mock_data.py`

```python
"""测试用Mock数据"""

# Mock AI分析结果
MOCK_AI_ANALYSIS_RESULT = {
    "issues": [
        {
            "id": 1,
            "type": "grammar",
            "description": "语法错误：缺少主语",
            "location": "第1行",
            "severity": "medium",
            "confidence": 0.85,
            "suggestion": "添加主语使句子完整"
        },
        {
            "id": 2,
            "type": "logic",
            "description": "逻辑矛盾：前后描述不一致",
            "location": "第3段",
            "severity": "high",
            "confidence": 0.92,
            "suggestion": "检查并修正矛盾的描述"
        }
    ],
    "summary": {
        "total_issues": 2,
        "high_severity": 1,
        "medium_severity": 1,
        "low_severity": 0
    }
}

# Mock文档内容
MOCK_DOCUMENT_CONTENT = """
# 测试文档

这是一个用于测试的文档。

## 功能介绍

系统具有以下功能：
1. 文档上传
2. 自动分析
3. 问题检测

## 使用说明

请按照以下步骤操作：
1. 登录系统
2. 上传文档
3. 等待分析完成
"""

# Mock用户数据
MOCK_ADMIN_USER = {
    "id": 1,
    "uid": "admin",
    "display_name": "管理员",
    "email": "admin@test.com",
    "is_admin": True,
    "is_system_admin": True
}

MOCK_NORMAL_USER = {
    "id": 2,
    "uid": "user001",
    "display_name": "普通用户",
    "email": "user001@test.com",
    "is_admin": False,
    "is_system_admin": False
}

# Mock任务数据
MOCK_TASK = {
    "id": 1,
    "title": "测试任务",
    "file_name": "test.md",
    "status": "pending",
    "progress": 0,
    "user_id": 1,
    "model_id": 1
}
```

### 6.3 测试辅助工具

**文件**: `tests/fixtures/test_helpers.py`

```python
"""测试辅助工具函数"""

import json
import tempfile
from pathlib import Path
from typing import Dict, Any

def create_temp_file(content: str, suffix: str = ".md") -> str:
    """创建临时测试文件"""
    with tempfile.NamedTemporaryFile(mode='w', suffix=suffix, delete=False) as f:
        f.write(content)
        return f.name

def assert_response_format(response_data: Dict[str, Any], expected_fields: list):
    """验证响应数据格式"""
    for field in expected_fields:
        assert field in response_data, f"响应缺少字段: {field}"

def assert_error_response(response_data: Dict[str, Any]):
    """验证错误响应格式"""
    assert "detail" in response_data, "错误响应缺少detail字段"
    assert isinstance(response_data["detail"], str), "detail字段应该是字符串"

def create_large_content(size_mb: int) -> str:
    """创建指定大小的测试内容"""
    chunk = "这是测试内容。" * 1000  # 约7KB
    chunks_needed = (size_mb * 1024 * 1024) // len(chunk.encode('utf-8'))
    return chunk * chunks_needed

def measure_execution_time(func, *args, **kwargs):
    """测量函数执行时间"""
    import time
    start_time = time.time()
    result = func(*args, **kwargs)
    end_time = time.time()
    execution_time = (end_time - start_time) * 1000  # 转换为毫秒
    return result, execution_time

class MockAIService:
    """AI服务Mock类"""
    
    def __init__(self, response_data=None):
        self.response_data = response_data or {
            "issues": [],
            "summary": {"total_issues": 0}
        }
    
    async def analyze_document(self, content: str) -> Dict[str, Any]:
        """模拟文档分析"""
        # 模拟处理延迟
        import asyncio
        await asyncio.sleep(0.1)
        
        return self.response_data
    
    def set_response(self, response_data: Dict[str, Any]):
        """设置Mock响应数据"""
        self.response_data = response_data
```

---

## 7. 测试配置优化

### 7.1 pytest.ini配置

```ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

addopts = 
    --strict-markers
    --strict-config
    --disable-warnings
    --cov=app
    --cov-report=html:htmlcov
    --cov-report=term-missing
    --cov-fail-under=80
    -v

markers =
    unit: 单元测试
    integration: 集成测试
    e2e: 端到端测试
    performance: 性能测试
    security: 安全测试
    slow: 运行时间较长的测试

filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
```

### 7.2 测试依赖文件

**文件**: `tests/requirements.txt`

```txt
# 测试框架
pytest>=7.0.0
pytest-asyncio>=0.21.0
pytest-cov>=4.0.0
pytest-mock>=3.10.0
pytest-xdist>=3.0.0
pytest-benchmark>=4.0.0

# 测试工具
factory-boy>=3.2.0
faker>=18.0.0
hypothesis>=6.70.0

# Mock和存根
responses>=0.23.0
httpx>=0.24.0
websocket-client>=1.5.0

# 数据生成
mimesis>=7.0.0
```

---

## 8. 实施指导

### 8.1 实施优先级

1. **第一阶段（1周）**：核心单元测试
   - TaskProcessor测试
   - DocumentProcessor测试
   - IssueDetector测试

2. **第二阶段（1-2周）**：Repository测试
   - 所有Repository的CRUD测试
   - 数据验证测试

3. **第三阶段（2-3周）**：集成和安全测试
   - AI服务集成测试
   - 安全测试用例

4. **第四阶段（3-4周）**：性能和高级测试
   - 性能基准测试
   - 并发测试

### 8.2 测试执行命令

```bash
# 运行所有测试
pytest

# 运行单元测试
pytest tests/unit/ -m unit

# 运行集成测试
pytest tests/integration/ -m integration

# 运行性能测试
pytest tests/performance/ -m performance

# 运行安全测试
pytest tests/security/ -m security

# 运行特定模块测试
pytest tests/unit/services/test_task_processor.py

# 生成覆盖率报告
pytest --cov=app --cov-report=html

# 并行执行测试
pytest -n auto
```

通过实施以上测试用例补充清单，预期可以将测试覆盖率从当前的约40%提升到80%以上，显著提高系统的可靠性和可维护性。